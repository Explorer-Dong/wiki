---
title: Accelerator
status: new
---

本文介绍市面上常见的计算卡。

## GPU

图形处理器 (Graphics Processing Unit, GPU) 是一种专门在个人电脑、工作站、游戏机和一些移动设备上执行绘图运算工作的微处理器。以图形处理器为核心的主板扩展卡一般称之为显卡。传统的 CPU 专为通用计算而设计，内核数量较少；相反，GPU 是一种特殊类型的处理器，具有数百或数千个内核，可并行运行大量计算。虽然 GPU 在游戏中以 3D 渲染而闻名，但它们对深度学习算法尤其有用。一般来说，以 GPU 为核心的显卡都代指 NVIDIA 系列，简称 N 卡。

各显卡在 AI 相关核心指标上的对比：

|     指标      |  H200  |  H100  |  H800  | A100  | A800  | RTX 5090 | RTX 4090 | V100  |
| :-----------: | :----: | :----: | :----: | :---: | :---: | :------: | :------: | :---: |
|  CUDA 核心数  | 16,896 | 14,592 | 14,592 | 6,912 | 6,912 |  21,760  |  16,384  | 5,120 |
| 显存容量 (GB) |  141   |   80   |   80   |  80   |  80   |    32    |    24    |  32   |

指标解释：

- **CUDA 核心数**：GPU 的通用计算单元数量，类似 CPU 的核心数，用于执行基本浮点或整数运算；
- **显存容量**：影响能容纳的模型大小与 batch size，显存不足需要分布式切分。

显卡型号解释：

- **H200（Hopper 架构强化版）**：在 H100 基础上升级为 HBM3e 内存（141GB, 4.8TB/s），主要针对超大模型推理与长上下文训练。它能在推理任务中显著减少显存溢出，是当前效率最高的单卡推理 GPU。
- **H100（Hopper 架构）**：支持 FP8 和 Transformer Engine，是目前全球顶级 AI 训练 GPU，用于 GPT-4 等超大模型。
- **H800（中国特供版）**：H100 的限带宽版本，NVLink 降至 400 GB/s，为中国市场的合法替代方案。
- **A100（Ampere 架构）**：AI 训练标准卡，支持 TF32/BF16 混合精度，兼具高通用性与高算力。
- **A800（中国特供版）**：A100 的限带宽版本，NVLink 降至 400 GB/s，以符合出口管制政策。
- **RTX 5090（Blackwell 架构）**：下一代消费级 GPU，预计支持 FP8，能效和显存带宽大幅提升，或成为个人开发者训练/推理的高性价比卡。
- **RTX 4090（Ada 架构）**：消费级旗舰 GPU，主要用于游戏和中小型 AI 训练/推理实验，算力强但显存较小、无多卡互联。
- **V100（Volta 架构）**：首款具备 Tensor Core 的数据中心 GPU，开启了深度学习硬件加速时代。
